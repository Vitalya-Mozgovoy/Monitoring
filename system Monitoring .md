# Домашнее задание Системы мониторинга

## Обязательные задания

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя 
платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой 
осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы
выведите в мониторинг и почему?

**Решение**

- __мониторинг операционной системы__:
  - процессор:
    - load average
  - память:
    - usage
  - диск:
    - объем данных
    - скорость записи/чтения
    - количество inodes
  - сеть:
    - загруженность интерфейсов
- __мониторинг задействованных сервисов (субд, веб-серверов, файловые хранилища)__:
  - доступность
  - загруженность
  - наличие ошибок
  - время отклика
- __мониторинг приложения__:
  - HTTP-запросы:
    - общее количество запросов
    - количество ошибочных запросов
    - время выполнения запросов
  - операции расчета и вывода данных:
    - количество операций
    - статус операций
    - время исполнения операций

---

2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, 
что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы 
можете ему предложить?

**Решение**

Нужно уточнить, какие обязательства фигурировали в договоре с клиентами, либо же какой уровень обслуживания декларировался. Затем привести собранные метрики к этим задекларированным индикаторам. Для описанной системы такими индикаторами могут быть:

- доступность системы в процентах;
- время выполнения запрошенной клиентом операции (минимальное, среднее и максимальное)
- допустимый процент ошибок

---

3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою 
очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, 
чтобы разработчики получали ошибки приложения?

**Решение**

Ни одно серьезное решение не возможно без бюджета...
- сэкономить на системе логирования можно, если переложить эту задачу на бюджет разработки, заставив программистов переделать код так, чтобы он работал с Sentry и выдавал не только ошибку приложения, но и весь необходимый контекст из других связанных сервисов. 
- Можно также предложить систематизировать ошибки приложения, договорившись, чтобы приложение отдавало определенный error code при возникновении той или иной ошибки. Такой код можно превратить в метрику, и по крайней мере отслеживать количество тех или иных ошибок, а также аномалии в этой величине. Это решение подразумевает, что затраты DevOps ограничатся лишь добавлением некоторого количества новых правил в существующую систему сбора метрик, но тем не менее потребуются затраты на рефакторинг подсистемы логирования в приложении. 
- Можно предложить построить урезанную схему сбора логов. Например,
    - собирать только записи с severity:ERROR;
    - собирать ошибки только с минимального количества необходимых приложений;
    - собирать ошибки не со всех реплик запущенного приложения, а только с ограниченного набора;
    - хранить логи минимально необходимый период времени;
    - настроить алертинг и триггеры, которые бы срабатывали во время ошибки и собирали бы дополнительную информацию.
  Эта схема позволит отлавливать определенный процент ошибок, а также позволит масштабировать схему до полноценной, когда на это будут выделены ресурсы.

---

4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. 
Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 
70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?

**Решение**

Нужно собрать информацию обо всех имеющихся в логах кодах ответов. Вероятнее всего 30% запросов завершаются с кодами 100-199 (informational) или кодами 300-399 (redirectional), в общем случае не являющимися ошибочными. Их нужно либо добавить в числитель выражения, либо вычесть из знаменателя.

---

## Обязательные задания

1. Опишите основные плюсы и минусы pull и push систем мониторинга.

**Решение**


__push model__:

  __плюсы__:
  - не требует открытия входящих портов на агентах;
  - можно обеспечить высокую сетевую производительность, используя udp;
  - гибкая настройка агентов в части обмена трафиком.

  __минусы__:
  - полное отсутствие информации о состоянии агента, если он не присылает метрики;
  - сложнее контролировать подлинность данных;

__pull model__:

  __плюсы__:
  - есть возможность централизованно выбирать агенты, с которых требуется собирать метрики;
  - простой протокол сбора метрик, легко повторить вручную при дебаге;

  __минусы__:
  - требуется дополнительный механизм обновления списка объектов мониторинга (discovery);
  - необходимо открывать входящие порты на объектах мониторинга;
  - плохо ложится на событийную модель сбора метрик, например, для сбора результатов исполнения каких-то разовых задач;
---

2. Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?

**Решение**

  - __Prometheus__: основным является pull; push лимитирован, требуется pushgateway
  - __TICK__: push или pull в зависимости от возможностей input плагина;
  - __Zabbix__: push или pull;
  - __VictoriaMetrics__: основным является pull через vmagent, но есть и возможность push с использованием remote write;
  - __Nagios__: основной pull и дополнительный push в зависимости от агента;

---

3. Склонируйте себе [репозиторий](https://github.com/influxdata/sandbox/tree/master) и запустите TICK-стэк, 
используя технологии docker и docker-compose.

В виде решения на это упражнение приведите выводы команд с вашего компьютера (виртуальной машины):

    - curl http://localhost:8086/ping
    - curl http://localhost:8888
    - curl http://localhost:9092/kapacitor/v1/ping

А также скриншот веб-интерфейса ПО chronograf (`http://localhost:8888`). 

P.S.: если при запуске некоторые контейнеры будут падать с ошибкой - проставьте им режим `Z`, например
`./data:/var/lib:Z`

**Решение**

```console
vagrant@vagrant> curl http://localhost:8086/ping?verbose=true
{"version":"1.8.10"}

vagrant@vagrant> curl http://localhost:8888
<!DOCTYPE html><html><head><meta http-equiv="Content-type" content="text/html; charset=utf-8"><title>Chronograf</title><link rel="icon shortcut" href="/favicon.fa749080.ico"><link rel="stylesheet" href="/src.9cea3e4e.css"></head><body> <div id="react-root" data-basepath=""></div> <script src="/src.a969287c.js"></script> </body></html>

vagrant@vagrant> curl -v http://localhost:9092/kapacitor/v1/ping
*   Trying 127.0.0.1:9092...
* Connected to localhost (127.0.0.1) port 9092 (#0)
> GET /kapacitor/v1/ping HTTP/1.1
> Host: localhost:9092
> User-Agent: curl/7.78.0
> Accept: */*
> 
* Mark bundle as not supporting multiuse
< HTTP/1.1 204 No Content
< Content-Type: application/json; charset=utf-8
< Request-Id: 49cfadca-fe23-11ec-8097-000000000000
< X-Kapacitor-Version: 1.6.4
< Date: Thu, 07 Jul 2022 18:33:25 GMT
< 
* Connection #0 to host localhost left intact

```

![telegaf](assets/img/telegraf.png)

---

4. Перейдите в веб-интерфейс Chronograf (`http://localhost:8888`) и откройте вкладку `Data explorer`.

    - Нажмите на кнопку `Add a query`
    - Изучите вывод интерфейса и выберите БД `telegraf.autogen`
    - В `measurments` выберите mem->host->telegraf_container_id , а в `fields` выберите used_percent. 
    Внизу появится график утилизации оперативной памяти в контейнере telegraf.
    - Вверху вы можете увидеть запрос, аналогичный SQL-синтаксису. 
    Поэкспериментируйте с запросом, попробуйте изменить группировку и интервал наблюдений.

Для выполнения задания приведите скриншот с отображением метрик утилизации места на диске 
(disk->host->telegraf_container_id) из веб-интерфейса.

**Решение**

![disk](assets/img/disk.png)

---

5. Изучите список [telegraf inputs](https://github.com/influxdata/telegraf/tree/master/plugins/inputs). 
Добавьте в конфигурацию telegraf следующий плагин - [docker](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker):
```
[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
```

Дополнительно вам может потребоваться донастройка контейнера telegraf в `docker-compose.yml` дополнительного volume и 
режима privileged:
```
  telegraf:
    image: telegraf:1.4.0
    privileged: true
    volumes:
      - ./etc/telegraf.conf:/etc/telegraf/telegraf.conf:Z
      - /var/run/docker.sock:/var/run/docker.sock:Z
    links:
      - influxdb
    ports:
      - "8092:8092/udp"
      - "8094:8094"
      - "8125:8125/udp"
```

После настройке перезапустите telegraf, обновите веб интерфейс и приведите скриншотом список `measurments` в 
веб-интерфейсе базы telegraf.autogen . Там должны появиться метрики, связанные с docker.

Факультативно можете изучить какие метрики собирает telegraf после выполнения данного задания.

**Решение**

![docker_metrics](assets/img/docker_metrics.png)

---